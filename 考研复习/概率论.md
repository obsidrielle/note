****## 1. 随机事件和概率
### 1.1 事件关系和运算
1. 吸收率: 若 $A \subset B,则 A \cup B = B, A \cap B =A$
2. 交换律
3. 结合率：若 $(A \cup B) \cup C = A \cup (B \cup C), (A \cap B) \cap C = A \cap (B \cap C)$
4. 分配率: $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$, 对减，并也成立。
5. 德摩根律: $\overline{A \cap B}= \bar{A} \cup \bar{B},\overline{A \cup B} = \bar{A} \cap \bar{B}$
其他:
$AB=\overline{A} \ \overline{B},A+BC=(A+B)(A+C),A-B=A \overline{B}=A-AB$
$AB \cup \overline{AB} = \omega \to A \cup B = \omega$
也可以使用**韦恩图**。
### 1.2 概率公式
$P(A|B)=\dfrac{P(AB)}{P(B)},P(\overline{B}|A)=1-P(B|A),P[(B-C)|A]=P(B|A)-P(BC|A)$
$P(A+B)=P(A)+P(B)-P(AB)$
$P(A_{1}A_{2}\dots A_{n})=P(A_{1})P(A_{2}|A_{1})P(A_{3}|A_{1}A_{2})\dots P(A_{n}|A_{1}A_{2}\dots A_{n-1})$
全概率公式：达成一个事件有 $n$ 条路，那么概率就是从起点走到中间点，再从中间点走到终点的概率乘积的和。
$$
P(B)=\sum^{n}_{i=1}P(A_{i})P(B|A_{i})
$$
贝叶斯公式:
从某条路走过的概率:
$$
P(A_{j}|B)= \dfrac{P(A_{j})P(B|A_{j})}{\sum^{n}_{i=1}P(A_{i})P(B|A_{i})}
$$
**如果 $A = 空事件 \to P(A)=0$**，反之不一定成立。
注意条件概率的公式使用时要考虑**分母**不为 $0$.

### 1.3 独立性
$AB 独立 \iff P(AB)=P(A)P(B) \iff   \bar{A}B 独立 \iff  A\bar{B}独立 \iff  \bar{A} \bar{B} 独立$
独立不具有传递性，两两独立不能推出全都独立。
不可能事件和必然事件和任意事件都独立。
对独立事件组不含相同事件运算，得到的事件组仍然独立。
$A,B,C,D 独立 \implies A,BC 独立 \implies AD, B-C独立$

## 2. 一维随机变量及其分布
分部函数的性质：
1. 单调不减
2. 右连续，也就是 $\lim_{ x \to x^-_{0} }F(x)=F(x_{0}+0)=F(x_{0})$
3. $F(-\infty)=0,F(+\infty)=1$
分部函数求概率
$P\left\{ X \leq a \right\}=F(a),P\left\{ X<a \right\}=F(a-0),P\left\{ X=a \right\}=F(a)-F(a-0)$
$P\left\{ a \leq X \leq b \right\}=F(b)-F(a-0)$

### 2.1 离散型随机变量和连续性随机变量
离散型随机变量只取有限个值。
连续性随机变量分布函数可以表示为
$$
F(x)=\int^{x}_{-\infty}f(t)dt
$$
而 $f(x)$ 是它的概率密度函数，有 $\int^{\infty}_{-\infty}f(x)=1$。
连续性随机函数在单点无概率。

### 2.2 常见的随机变量分布类型
1. $0-1$ 分布 $B(1,p)$
2. 二项分布 $B(n,p)$
$$
P\left\{ X=k \right\}=C^k_{n}p^k(1-p)^{n-k} 
$$
当 $k=(n+1)p或k=(n+1)p-1$ 其中一个取最大值。

3. 泊松分部 $P(\lambda)$
$$
P\left\{ X=k \right\} =\dfrac{\lambda^k}{k!}e^{-\lambda} 
$$
泊松定理：当 $X \sim B(n,p),n很大，p很小，np适中时，使用泊松分部近似二项分布$。
4. 几何分部 $G(p)$
$$
P = \left\{ X=k \right\}=(1-p)^{k-1}p 
$$
几何分布有无记忆性。
其意义是，实验了 $k$ 次，最后一次成功的概率。
5. 超几何分布 $H(n,N,M)$
一般使用二项分布近似。
6. 均匀分布 $U(a,b)$
$$
f(x)= \left\{\begin{align}\dfrac{1}{b-a},a<x<b \\
0, 其他
\end{align}\right.
$$
7. 指数分部 $E(\lambda)$
$$
f(x)= \left\{\begin{align} \lambda e^{-\lambda x},x>0 \\
0, 其他
\end{align}\right.
$$
指数分布有无记忆性，有 $P\left\{ X \geq S+T | X \geq S\right\}=P\left\{ X\ge T \right\}$。
8. 正态分布 $N(\lambda,\sigma^2)$
$$
f(x)= \dfrac{1}{\sqrt{ 2\pi }\sigma} e^{-\dfrac{1}{2}(\dfrac{x-\mu}{\sigma})^2}
$$
$N(0,1)$ 是标准正态分布。其分部函数是 $\phi(x)=\dfrac{1}{\sqrt{ 2\pi }}\int^{x}_{-\infty}e^{-\dfrac{t^2}{2}}dt$
对于 $X \sim N(\mu, \sigma^2),\dfrac{x-\mu}{\sigma} \sim N(0,1)$，所以对于正态分部题最重要的步骤是先标准化。

### 2.3 一维随机变量函数的分布
常用分布函数法
已知 $X$ 的分布 $F(X)$
1. $2X$ 的分布
$$
Z=2X,F_{z}(Z)=P \left\{ Z\leq z \right\}=P \left\{ 2X  \leq z\right\}=P\left\{ X \leq \dfrac{z}{2} \right\}   
$$
由此换成已知 $X$ 的分布。
2. $X^2$ 的分布
$$
Z=X^2,F_{z}(Z)=P\left\{ Z\leq z \right\}=P\left\{ X^2\leq z \right\}=P \left\{ -\sqrt{ z } \leq X \leq \sqrt{ z } \right\}   
$$
处理方法都是一样的。

## 3 多维随机变量及其分布
联合分布函数依然有单调性，右连续，非负，有界。
边缘分布函数
$$
F_{x}(X)=P \left\{ X\leq x \right\}=P \left\{ X\leq x, Y < +\infty \right\}=\lim_{ y \to \infty } F(x,y)=F(x,+\infty)   
$$
$$
F_Y(y)=F(+\infty,y)
$$
条件分布函数
$$
P\left\{ X=x_{i} | Y=y_{i} \right\}=\dfrac{P_{ij}}{P_{kj}} 
$$
其中 $k$ 是一个特定的值。
另外，有边缘分布函数乘以条件分布函数等于联合分布函数。

对于连续随机变量
联合分布函数
$$
F(x,y)=\int^{y}_{-\infty}dv \int^{x}_{-\infty}f(u,v)du
$$
其中 $f(u,v)$ 是其概率密度函数函数。
有
$$
f(x,y)\geq 0, \int^{+\infty}_{-\infty} dy \int^{+\infty}_{-\infty} f(x,y)dx=1
$$

边缘概率密度
$$
f_{X}(x)=\int^{+\infty}_{-\infty} f(x,y)dy, f_{Y}(y)=\int^{+\infty}_{-\infty}f(x,y)dx
$$
注意这里积分变量是另外一个。
求法是当成二重积分来求，比如要求 $f_{X}$, 就把 $y$ 积起来，对于每个 $x$ 去看 $y$ 是多少，相当于二重积分里面后积 $X$, 因此不用管
比如
$$
\int^{1}_{0}dx \int^{2x}_{0}dy
$$
就直接取 $\int^{2x}_{0}dy$.

比如要 $x$ 的边缘概率，等于固定了 $x$, 然后把 $y$ 积起来。$x$ 当作是函数的取值范围。

例:
$$
f(x,y)=\left\{\begin{align}&1,
0<x<1,-x<y<x \\
&0,其他\end{align}\right.
$$
求 $f_Y(y)$。
类比二重积分的积分办法，要求 $f_{Y}(y)$，则 $y$ 的取值范围是 $-1<y<1$。
固定 $y$, 在 $0<y<1$, 有 $x=y$，因此有
$$
f_{Y}(y)=\int^{1}_{y}1dx=1-y
$$
同理在 $-1<y<0$，有 $f_{Y}(y)=1+y$。
因此
$$
f_{Y}(y)= 1-|y|,-1<y<1
$$


条件概率密度
$X=x$ 条件下的条件概率密度
$$
f_{Y|X}(y|x)=\dfrac{f(x,y)}{f_{X}(x)}
$$
同理定义 $Y=y$ 下的条件概率密度
$$
f_{X|Y}(x|y)=\dfrac{f(x,y)}{f_{Y}(y)}
$$
同样也有 $f(x,y)=f_{X}(x)f_{Y|X}(y|x)=f_{Y}(y)f_{X|Y}(x|y)$。
**在这里，直接拼起来两个变量的取值范围即可**，比如对于 $X$ 有 $0<x<1$, 对于 $Y$ 有 $-x < y<x$。
那么 $f(x,y)$ 范围就是 $0<x<1,-x<y<x$。

用整体分布函数先对 $x$ 偏导再对 $y$ 偏导可以得到联合概率密度。

### 3.1 常见的二维分布
1. 二维均匀分布
$$
f(x,y)=\left\{\begin{align} \dfrac{1}{S_{P}},(x,y) \in D \\
0,  其他
\end{align}\right.
$$
2. 二维正态分布
记为 $(X_{1},X_{2}) \sim N(\mu_{1},\mu_{2};\sigma^2_{1},\sigma_{2}^2;\rho)$
其中第五个参数是相关系数，如果为 $0$ 说明这两个正态分布相互独立。
对于多维正态分布，不相关等价于独立。
如果 $(X_{1},X_{2}) \sim N$, 则 $k_{1}X_{1}+k_{2}X_{2} \sim N$, $k_{1},k_{2}$ 是不全为 $0$ 的常数。
$$
C= \left ( \begin{matrix}\sigma^2_{1} & \rho \sigma_{1}\sigma_{2} \\
\rho \sigma_{1}\sigma_{2} & \sigma^2_{2}
 \end{matrix}\right )
$$
$$
f(x,y)=\dfrac{1}{2\pi \sqrt{ |C| }}\exp \left\{ -\dfrac{1}{2}(\vec{X}-\vec{\mu})^TC^{-1}(\vec{X}-\vec{\mu}) \right\} 
$$

### 3.2 随机变量的相互独立性
独立性的判别：
$$
F(x,y)=F_{X}(x)F_{Y}(y)或f(x,y)=f_{X}(x)f_{Y}(y)
$$
不独立的判别:
任意取值不满足上式即可，一般来说，独立的条件是**概率密度函数区域是矩形且函数表达式可分离**。

### 3.3 多维随机变量函数的分布
如果是两个离散型，直接使用分布列求解，
如果是一个离散型一个连续型，根据分布列化为几个连续型随机变量，再分别求解后使用全概率公式得到分布。
如果是两个连续型：
1. 使用分布函数法
已知 $f(x,y)$
求 $Z=X+Y$ 的分布
$$
P\left\{ Z \leq z\right\} =P \left\{ X+Y \leq z \right\} = \iint_{x+y\leq z}f(x,y)dxdy
$$
求 $g(X,Y)$ 的分布
$$
F(z)=\iint_{g(x,y)\leq z}f(x,y)dxdy
$$
再求导得到概率密度。
如果知道 $f(x,y)$ 反过来求 $F(x,y)$ 的分布函数，可能会需要根据 $x<y或者x>y$ 进行分界。

2 使用卷积公式法
口诀是**积谁不换谁，换完求偏导**
求 $Z=X+Y$ 的分布
$$
f_{z}(Z)=\int^{+\infty}_{-\infty}f(x,z-x)\left| \dfrac{\partial(z-x)}{\partial z} \right| dx=\int^{\infty}_{-\infty}f(z-y,y) \left| \dfrac{\partial (z-y)}{\partial z} \right| 
$$
求 $Z=\dfrac{X}{Y}$ 的分布
$$
f_{z}(Z)=\int^{+\infty}_{-\infty} f(yz,y) \left| \dfrac{\partial (yz)}{\partial z} \right|  dy
$$
注意是对 $z$ 求偏导。

**关于分界点**
如果有 $0<y<1,0<x<1$, 求 $Z=X+Y$ 的分布。
有 $y=z-x$。
则有
$$
\left\{\begin{align}0<x<1 \\
0<y<1 \to z-1 < x < z
\end{align}\right.
$$
然后对上述两个等式，进行交叉相等。
$$
\left\{\begin{align}z-1=0 \\
z=1 \\
z-1=1 \\
z=0
\end{align}\right.
$$
解出分界点 $z=0,1,2$
如果是 $-x<x-z<x$, 则 $-z<0\to z>0$ 也是一个必要的限制条件。

求 $\mathrm{\max}(X,Y)$ 分布
$\max(X,Y)\leq z$ 也就是两者的较小者比 $z$ 小
$$
F(z)=P \left\{ x\leq z,Y\leq z \right\}=F(z,z) 
$$
求 $\min(X,Y)$ 分布
$\min(X,Y)\leq z$ 也就是两者的较大值比 $z$ 小
$$
F(z)=P \left\{ \left\{ X \leq z \right\} \cup \left\{ Y\leq z \right\}   \right\}=1-P \left\{ X>z,Y>z \right\}=1-(1-F_{x}(Z))(1-F_{y}(Z)) ，如果独立
$$
如果反过来，$min(X,Y) \geq z$ 就是两者都要大于 $z$。

如果有多个独立同分布的 $X_{1\dots n}$
则 $max(\left\{ X_{i} \right\})$ 的分布函数是 $\left[ F(X_{i}) \right]^n$
$min(\left\{ X_{i} \right\})$ 的分布函数是 $1-\left[ 1-F(X_{i}) \right]^n$ 

全概率计算分布：
例：设 $X_{1}$ 取 $1,0$ 的概率都是 $0.5$, $X_{2}$ 满足标准正态，设 $Y=2X_{1}X_{2}-X_{2}$。求 $Y$ 的分布。
写法：
$$
\begin{align}
P \left\{ Y \leq y \right\} &= P \left\{ 2X_{1}X_{2}-X_{2} \leq y |X_{1} = 1  \right\} + P \left\{ 2X_{1}X_{2}-X_{2} \leq y | X_{1} = 0 \right\} \\
&= \dfrac{1}{2}P \left\{ X_{2} \leq y  \right\} +\dfrac{1}{2} P \left\{ X_{2} \geq -y \right\} = P \left\{ X_{2} \leq y \right\} = \Phi (y)     
\end{align}
$$
即 $Y$ 服从标准正态分布。

对于同一个变量的二维，化成一维:

$$
P\left\{ T\geq x,2-T \geq x \right\} = P \left\{ x \leq T \leq 2 -x \right\}  
$$

> 绝对值的卷积公式

先求不带绝对值的概率密度 $f_{Z}(z)$, 最后结果就是 $f_{Z}(z)+f_{Z}(-z)$, 只取 $z>0$.

推导:
设 $U=|Z|$, 于是 $F_{U}(u)=P\left\{ U \leq u \right\}= P\left\{ -u \leq Z \leq u \right\}=F_{Z}(u)-F_{Z}(-u)$.
求导得 $F_{U}(u)=f_{Z}(u)+f_{Z}(-u)$.

设 $X,Y$ 相互独立，且均服从参数为 $1$ 的指数分布，求 $Z=|X-Y|$ 的分布.

$U=X-Y\implies X=U+Y$. 范围是 $x>0,y>0$, 即 $u>-y,u>0$.

1. $u>0$.

$$
f_{U}(u)=\int^{+\infty}_{0}e^{-(2y+u)}dy = \dfrac{1}{2}e^{-u}
$$
2. $u<0$
$$
f_{U}(u)=\int^{+\infty}_{-u}e^{-(2y+u)}dy = \dfrac{1}{2}e^{u}
$$
故
$$
f_{U}(u) = \dfrac{1}{2}e^{-|u|},f_{U}(-u)=\dfrac{1}{2}e^{-|u|}=f_{U}(u)
$$
故
$$
f_{Z}(z)=f_{U}(u)+f_{U}(-u) = e^{z}
$$
即 $Z\sim E(1)$.

### 3.4 常见分布的可加性
$X \sim B(n,p), Y \sim (m,p) \to X+Y \sim B(n+m,p)$
$X \sim P(\lambda_{1}), Y \sim P(\lambda_{2}) \to X+Y \sim P(\lambda_{1}+\lambda_{2})$
$X \sim N(\mu_{1},\sigma_{1}^2), Y \sim N(\mu_{2},\sigma_{2}^2), \to X+Y \sim N(\mu_{1}+\mu_{2},\sigma_{1}^2+\sigma_{2}^2), X-Y \sim N(\mu_{1}-\mu_{2}, \sigma_{1}^2+\sigma_{2}^2)$
$X \sim \chi^2(n),Y \sim \chi^2(m) \to X+Y \sim \chi^2(n+m)$

## 4. 随机变量的数字特征
期望:
$$
E(g(x))=\int^{+\infty}_{-\infty}g(x)f(x)dx
$$
性质:
$E(a)=a,E(EX)=EX$
$E(aX+bY)=aEX+bEY, E \left( \sum^{n}_{i=1}a_{i}X_{i} \right)=\sum_{i=1}^n a_{i}EX_{}i$
若 $X,Y$ 相互独立，$E(XY)=EXEY$, 反之不一定成立，实际上 $E(XY)=E(X)E(Y)+Cov(X,Y)$
另外，期望中的函数满足分配率，由定义可知这是很显然的。
$E\left[ (X-EX)(Y-EY) \right]=E \left[ XY-XEY-YEX+EXEY \right]=E \left[ XY \right]-EXEY-EXEY+EXEY=E \left[ XY \right]-EXEY$
要求绝对值的期望，比如 $|X-Y|$ 的期望，可以设 $Z=X-Y$, 然后求 $|Z|$ 的期望。

例:
设 $X$ 服从参数为 $1$ 的泊松分布，求 $E(\dfrac{1}{x+1})$ 的期望
$$
E(\dfrac{1}{X+1})=\sum^{\infty}_{k=0}P \left\{ X=k \right\} \dfrac{1}{k+1} = \sum^{\infty}_{k=0}  \dfrac{e^{-1}}{(k+1)!} =1-\dfrac{1}{e} 
$$

方差
$$
D(X)=E \left[ (X-EX)^2 \right] =E(X^2)-(EX)^2
$$
有一些期望需要使用方差计算。

性质
$D(aX+b)=a^2D(X)$
$D(aX\pm bY)=a^2 DX+b^2DY\pm 2abCov(X,Y)$
$D \left( \sum^{n}_{i=1}a_{i}X_{i} \right)=\sum^{n}_{i=1}a^2_{i}DX_{i}+2\sum_{1 \leq i <j\leq n}a_{i}a_{j}Cov(X_{i},X_{j})$

### 4.1 常见分布的期望和方差
1. $0-1$ 分布
$E(X)=p,D(X)=p(1-p)$
2. 二项分布
$E(X)=np,D(X)=np(1-p)$
3. 泊松分布
$E(x)=\lambda,D(x)=\lambda$
4. 几何分布
$E(x)=\dfrac{1}{p},D(x)=\dfrac{1-p}{p^2}$
5. 均匀分布
$E(x)=\dfrac{a+b}{2},D(x)=\dfrac{(a-b)^2}{12}$
6. 指数分布
$E(x)=\dfrac{1}{\lambda},D(x)=\dfrac{1}{\lambda^2}$

### 4.2 二维随机变量的数字特征
$$
E \left[ g(X,Y) \right] = \int^{+\infty}_{-\infty} \int^{+\infty}_{-\infty}g(x,y)f(x,y)dxdy 
$$

对于一个二维随机变量，要单独求 $EX$ 或者 $EY$ 的期望，先求边缘密度，再求期望。
如果 $Y=f(X)$, 那么算 $E(XY)$ 直接代入 $E(Xf(X))$ 更方便。

协方差和相关系数
$$
Cov(X,Y)=E \left[ (X-EX)(Y-EY) \right] = E(XY)-EXEY
$$
$$
\begin{align}

\end{align}
$$
相关系数定义为
$$
\rho_{XY}=\dfrac{Cov(X,Y)}{\sqrt{ DX } \sqrt{ DY }}
$$
如果为 $0$ 称为不相关，如果不相关，有协方差为 $0$, 但是**不代表独立**。

性质
$Cov(X,Y)=Cov(Y,X)$
$Cov(aX,bY)=abCov(X,Y)$
$Cov(X_{1}+X_{2},Y_{1}+Y_{2})=\sum_{1 \leq i \leq 2, 1\leq j \leq 2}Cov(X_{i},Y_{j})$，自由两两组合。
$Cov(X+a,Y+b)=Cov(a,b)$
$Cov(X,X)=D(X)$

协方差可以帮助确定概率分布。
例:
设 $X \sim B(1,\dfrac{1}{4}),Y \sim B(1,\dfrac{1}{6}),Cov(X,Y)=\dfrac{1}{24}$
由 $Cov(X,Y)$ 得出 $E(XY)=\dfrac{1}{12}$，此时有 $X=Y=1$, 再根据概率和为一可以得出概率分布。

$\rho_{XY}=1$ **说明 $Y和aX+b$ 同分布**，如果 $\rho > 1$, 则 $a>0$, 否则 $a<0$。
如果要确定 $a,b$ 的值，有 $P \left\{ Y=aX+b \right\}=1$, 则必有 $E(aX+b)=aE(X)+b=E(Y),D(aX+b)=D(Y)$。

例:
设随机变量 $X$ 在 $[-1,1]$ 上服从均匀分布，$Y_{1}=\arcsin X,Y_{2}=\arccos X$ 则 $\rho_{Y_{1}Y_{2}}$
因为有 $\arcsin Y 1+\arccos Y_{2}=1 \to Y_{1}= \dfrac{\pi}{2}-Y_{2}$
所以 $\rho_{Y_{1}Y_{2}}=-1$。

不相关性的判别
$$
\rho_{XY}=0 \iff Cov(X,Y)=0 \iff E(XY)=EXEY \iff D(X\pm Y)= DX+DY
$$
如果独立一定不相关，但是反之不一定成立。

###  4.3 切比雪夫不等式
对任意 $\epsilon > 0$ 有
$$
P \left\{  |X-EX| \geq \epsilon \right\} \leq \dfrac{DX}{\epsilon^2} 
$$
其意义是，偏离期望的距离越高，概率越小。
如果是双边的不等式，需要收成绝对值的形式。
比如 $EX=11$, 那么 $6<\sum < 16 \to |\sum - 11| < 5$

## 5. 大数定律和中心极限定理
1. 依概率收敛
设随机变量 $X$ 和随机变量序列 $\left\{ X_{n} \right\}$, 如果对任意 $\epsilon>0$,
有
$$
\lim_{ n \to \infty } P \left\{ |X_{n}-X| \geq \epsilon \right\}=0 \ or \ \lim_{ n \to \infty } P \left\{ |X_{n}-X| < \epsilon\right\}=1    
$$
就说随机变量序列依概率收敛于 $X$。
记为
$$
X_{n} \xrightarrow{P} X(n \to \infty)
$$
2. 大数定律
切比雪夫大数定律
$\left\{ X_{i} \right\}$ 是**相互独立**的随机变量序列，**方差相同且有上界**，则样本均值依概率收敛于期望均值
$$
\dfrac{1}{n} \sum_{i=1}^n X_{i} \xrightarrow{P} \dfrac{1}{n} \sum^{n}_{i=1} EX_{i} 
$$
伯努利大数定律
随机变量 $X$ 满足二项分布 $B(n,p)$, 设 $\mu_{n}$ 是事件 $A$ 发生次数，则有 
$$
\dfrac{u_{n}}{n} \xrightarrow{P} p
$$
辛钦大数定律
随机序列 $\left\{ X_{n} \right\}$ 是**独立同分布**，如果期望存在， 则样本均值依概率收敛于期望。
$$
\dfrac{1}{n} \sum^{n}_{i=1} X_{i} \xrightarrow{P} \mu
$$

总结： 伯努利是二项分布，切比雪夫是来自不同的独立序列，方差都一样且有上界，辛钦是独立同分布。
3. 中心极限定理
列维-林德伯格定理
假设 $\left\{ X_{n} \right\}$ 是**独立同分布**的随机变量序列，
设 $EX_{i}=\mu,DX_{i}=\sigma^2$
当 $n$ 很大时，随机变量的和 $\sum^{n}_{i=1}X_{i}$ 近似服从正态分布 $N(n \mu, n \sigma^2)$ 。
也就是 
$$
\dfrac{\sum^{n}_{i=1}X_{i}-n \mu}{\sqrt{  n } \sigma} \sim N(0,1)
$$

拉普拉斯定理
设随机变量 $Y_{n} \sim B(n,p)$
则有随机变量的和 $\sum^{n}_{i=1}Y_{i}$ 服从正态分布 $N(np,np(1-p))$。

## 6. 数理统计
### 6.1 统计量及其分布
$X_{1},X_{2},\dots,X_{n}$ 是来自总体的一个样本，$g(x_{1},x_{2},x_{3},\dots,x_{n})$ 是 $n$ 元函数，如果其中不含有任何未知参数，则是统计量。

常用统计量
1. 样本均值 $\bar{X}=\dfrac{1}{n}\sum^{n}_{i=1}X_{i}$
2. 样本方差 $S^2=\dfrac{1}{n-1} \sum^{n}_{i=1}(X_{i}-\bar{X})^2$
3. 样本 $k$ 阶原点矩 $A_{k}=\dfrac{1}{n} \sum^{n}_{i=1} X_{i}^k$
4. 样本 $k$ 阶中心矩 $B_{k}=\dfrac{1}{n} \sum^{n}_{i=1} (X_{i}-\bar{X})^k$
性质
$E \bar{X}=EX=\mu, D \bar{X}=\dfrac{1}{n} DX=\dfrac{\sigma^2}{n}, E(S^2)=DX=\sigma^2$ 

注:
样本方差 $S^2$ 是 $\sigma^2$ 的无偏估计，但是 $\dfrac{1}{n}\sum^{n}_{i=1}(X_{i}- \bar{X})^2$ 不是无偏估计。
因为已知均值 $\bar{X}$ 固定，所以 $X_{n}$ 可以由 $X_{1},\dots,X_{n-1}$ 线性表出，因此 $X_{n}$ 对自由度无贡献，所以自由度是 $n-1$。

### 6.2 三大分布
1. $\chi^2$ 分布
若随机变量 $X_{1},X_{2},\dots,X_{n}$ 相互独立且服从标准正态分布，则随机变量 $X=\sum^{n}_{i=1}X_{i}^2$ 服从自由度为 $n$ 的 $\chi^2$ 分布，$X \sim \chi^2(n)$。
性质
$X \sim \chi^2(n), EX=n,DX=2n$
$X_{1} \sim X^2(n), X_{2} \sim \chi^2(m) \to X_{1}+X_{2} \sim \chi^2(n+m)$
2. $t$ 分布
设 $X \sim N(0,1), Y \sim \chi^2(n)$, 且 $X,Y$ 相互独立，则 $t=\dfrac{X}{\sqrt{ \dfrac{Y}{n} }}$ 服从自由度为 $n$ 的 $t$ 分布，$t \sim t(n)$。
图像关于 $y$ 对称，因此 $t_{1-\alpha}(n)=-t_{\alpha}(n)$。
3. $F$ 分布
设 $X \sim \chi^2(n_{1}),Y \sim \chi^2(n_{2})$, $X,Y$ 相互独立，则 $F=\dfrac{\dfrac{X}{n_{1}}}{\dfrac{Y}{n_{2}}}$ 服从自由度为 $(n_{1},n_{2})$ 的 $F$ 分布，$F \sim F(n_{1},n_{2})$。
性质
$F \sim F(n_{1},n_{2}) \to \dfrac{1}{F} \sim F_{2}(n_{2},n_{1})$
$F_{1-\alpha}(n_{1},n_{2})=\dfrac{1}{F_{\alpha}(n_{2},n_{1})}$ ,注意这里 $n_{1},n_{2}$ 也相反。
$t \sim t(n) \to t^2 \sim F(1,n)$

上 $\alpha$ 分位数指的是 $P(X\geq x_{\alpha})=\alpha$, 也就是对于给定的 $\alpha$, 给出的值是对应的横坐标值。

### 6.3 正态总体条件下的常用结论
设 $X_{1},X_{2},\dots,X_{n}$ 是来自正态总体的一个样本，则
1. $\bar{X} \sim N(\mu, \dfrac{\sigma^2}{n})$
2. $\dfrac{1}{\sigma^2}\sum^{n}_{i=1}(X_{i}-\mu)^2 \sim \chi^2(n)$
3. $\dfrac{(n-1)S^2}{\sigma^2}=\sum^{n}_{i=1}(\dfrac{X_{i}-\bar{X}}{\sigma}) \sim \chi^2(n-1)$
4. $\bar{X}和S^2$ 相互独立（仅在正态总体），$\dfrac{\sqrt{ n }(\bar{X}- \mu)}{S} \sim t(n-1) \to \dfrac{n(\bar{X}-\mu)^2}{S^2}\sim F(1,n-1)$
有 $\dfrac{\bar{X}-\mu}{\dfrac{\sigma}{\sqrt{ n }}} \sim N(0,1)$, $\dfrac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$。
$X_{i}-\bar{X} \sim N(0, \dfrac{n-1}{n}\sigma^2)$.
另外样本方差是总体方差的无偏估计量，即 $E(S^2)=\sigma^2$。

### 6.4 参数的点估计
1. 矩估计
对于一个参数：
使用一阶矩有 $\bar{X}=EX$, 如果不可使用则用二阶矩建立 $\dfrac{1}{n}\sum X^2_{i}=E(X^2)$
对于两个参数：
用一阶矩和二阶矩建立方程。
2. 最大似然估计
写似然函数 $\Uppi^n_{i=1}f(x_{i}; \theta)$ (意思是把所有样本取值的概率乘起来即可), 然后取对数后求出驻点，然后用驻点和单调性判断。
要估值什么值，在取对数后就对什么值求导。
对于概率密度函数 $f(x)$, 取到的概率就是 $f(x_{i})$。

3. 估计量的评价标准
无偏性: $E \hat{\theta}=\theta$, 则为无偏估计。
有效性: 方差更小的更有效, $D \hat{\theta_{1}}<D \hat{\theta}_{2}$。
相合性: 有 $\hat{\theta} \xrightarrow{P} \theta$, 则是相合估计。(切比雪夫不等式或者辛钦大数定律)。

### 6.5 参数的区间估计
1. $\sigma^2$ 已知，$\mu$:
使用 $\dfrac{\bar{X}-\mu}{\sigma \sqrt{ n }} \sim N(0,1)$ ,这个也叫 $z$ 分布。
2. $\sigma^2$ 未知，$\mu$:
使用 $\dfrac{\sqrt{ n }(\bar{X}-\mu)}{S} \sim t(n-1)$
3. $\mu$ 已知，$\sigma^2$ :
使用 $\sum^{n}_{i=1}(\dfrac{X_{i}-\mu}{\sigma}) \sim \chi^2(n)$
4. $\mu$ 未知，$\sigma^2$
使用 $\dfrac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$

区间估计双侧区间开区间，单侧
### 6.6 假设检验
当事件发生的概率不大于显著性水平 $\alpha$ 时，就认为是小概率事件，因此如果说，小概率事件发生了，则证明假设是错误的，应当拒绝假设。同时 $\alpha$ 就是弃真的概率。也就是 $H_{0}$ 成立时进入拒绝率的感觉，也就是拒绝域越大对应越大的 $\alpha$。
如果检验 $H:\mu=\mu_{0}$, 则有双侧拒绝域，不能太大或者太小，如果 $H:\mu \geq \mu_{0}$, 则有单侧拒绝域，不能太小。

### 6.7 两类错误
第一类错误：弃真，若 $H_{0}$ 是真但是否定 $H_{0}$。
第二类错误：取伪，若 $H_{0}$ 不真但是接受 $H_{0}$。

可以使用条件概率计算这两种发生的概率。
例：

设 $X_{1},X_{2}$ 是来自正态总体 $N(\mu, 1)$ 的简单随机样本，设原假设 $H_{0}:\mu=2$, 备择假设 $H_{1}:\mu=4$, 若拒绝域 $W=\left\{ \bar{X} > 3 \right\}, \bar{X}=\dfrac{1}{2}\sum^2_{i=1}X_{i}$, 记 $\alpha,\beta$ 分别是犯第一类和第二类错误的概率，求 $\alpha,\beta$。
可知 $E(\bar{X})=\mu,D(\bar{X})=\dfrac{1}{2}$。
$$
\beta = P \left\{ \bar{X} \leq 3 | \mu = 4 \right\} =P \left\{ \dfrac{\bar{X}-4}{\dfrac{1}{\sqrt{ 2 }}} \leq \dfrac{3-4}{\dfrac{1}{\sqrt{ 2 }}} \right\} = \Upphi (-\sqrt{ 2 }) = 1- \Upphi(\sqrt{ 2 })  
$$
$$
\alpha = P \left\{ \bar{X} > 3 | \mu = 2 \right\} = P \left\{ \dfrac{\bar{X}-2}{\dfrac{1}{\sqrt{ 2 }}} > \dfrac{3-2}{\dfrac{1}{\sqrt{ 2 }}} \right\} = 1 - \Upphi(\sqrt{ 2 })  
$$

$$
6 \int^{2}_{0}\dfrac{1}{x^3+1} =2\int^{2}_{0}\dfrac{1}{1+x}-\dfrac{x-2}{x^2-x+1}
$$
$$
\int^{#}_{#}
$$